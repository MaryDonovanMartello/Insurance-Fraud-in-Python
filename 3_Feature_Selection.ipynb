{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Insurance Claim Fraud Indicators and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mary Donovan Martello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goal of this project was to identify significant features in fraudulent insurance claim transactions and to design predictive classification models to predict whether fraud was reported on the insurance claim transaction. This notebook includes feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3:  Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data set and libraries for data preparation phase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# importing regex module (search strings) RegEx can be used to check if a string contains the specified search pattern\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The original dataset includes 1,000 prior claim transaction records. Each record has a mix of 38 quantitative and categorical data features about the claim filed, including information on the policy, insured, and automobile, aspects of the damage incident, and elements of the claim filed. The dataset also has a feature that indicates whether fraud was reported on each observation (i.e., either Y or N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfClaims = pd.read_csv('FradulentInsuranceClaims.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "      <th>_c39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014-10-17           OH   \n",
       "1                 228   42         342868       2006-06-27           IN   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "\n",
       "   insured_zip  ... police_report_available total_claim_amount injury_claim  \\\n",
       "0       466132  ...                     YES              71610         6510   \n",
       "1       468176  ...                       ?               5070          780   \n",
       "\n",
       "  property_claim vehicle_claim  auto_make  auto_model auto_year  \\\n",
       "0          13020         52080       Saab         92x      2004   \n",
       "1            780          3510   Mercedes        E400      2007   \n",
       "\n",
       "  fraud_reported _c39  \n",
       "0              Y  NaN  \n",
       "1              Y  NaN  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfClaims.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset in this notebook includes the original data that was cleaned in the 1_EDA_Prep notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cleaned df without re-running the cleaning code\n",
    "df = pd.read_csv('dfClaims.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Prepare features to use in models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical data to numbers\n",
    "\n",
    "#get the categorical data\n",
    "cat_features = ['policy_state',\n",
    "       'insured_sex', 'insured_education_level', 'insured_occupation',\n",
    "       'insured_hobbies', 'insured_relationship', 'incident_type',\n",
    "       'collision_type', 'incident_severity', 'authorities_contacted',\n",
    "       'incident_state', 'incident_city', 'property_damage',\n",
    "       'police_report_available', 'auto_make', 'auto_model']\n",
    "df_cat = df[cat_features]\n",
    "\n",
    "# One Hot Encoding \n",
    "dfDumm = pd.get_dummies(df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the numerical features and the dummie features together\n",
    "dfNum = df.drop(['policy_state', 'incident_location',\n",
    "       'insured_sex', 'insured_education_level', 'insured_occupation',\n",
    "       'insured_hobbies', 'insured_relationship', 'incident_type',\n",
    "       'collision_type', 'incident_severity', 'authorities_contacted',\n",
    "       'incident_state', 'incident_city', 'property_damage',\n",
    "       'police_report_available', 'auto_make', 'auto_model', 'fraud_reported'], axis = 1)\n",
    "\n",
    "Xdumm = pd.concat([dfNum, dfDumm], axis=1)\n",
    "\n",
    "# create a whole target dataset that can be used for train and validation data splitting\n",
    "y =  df['fraud_reported']\n",
    "# for Random Forest when target is not label encoded\n",
    "yRF = df['fraud_reported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CART classification and Random Forest Classifier to determine important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.02258\n",
      "Feature: 1, Score: 0.02940\n",
      "Feature: 2, Score: 0.06283\n",
      "Feature: 3, Score: 0.00439\n",
      "Feature: 4, Score: 0.03036\n",
      "Feature: 5, Score: 0.00230\n",
      "Feature: 6, Score: 0.04263\n",
      "Feature: 7, Score: 0.00474\n",
      "Feature: 8, Score: 0.00657\n",
      "Feature: 9, Score: 0.01123\n",
      "Feature: 10, Score: 0.00000\n",
      "Feature: 11, Score: 0.00000\n",
      "Feature: 12, Score: 0.01869\n",
      "Feature: 13, Score: 0.01693\n",
      "Feature: 14, Score: 0.00931\n",
      "Feature: 15, Score: 0.01955\n",
      "Feature: 16, Score: 0.00499\n",
      "Feature: 17, Score: 0.02381\n",
      "Feature: 18, Score: 0.00000\n",
      "Feature: 19, Score: 0.00995\n",
      "Feature: 20, Score: 0.01840\n",
      "Feature: 21, Score: 0.00000\n",
      "Feature: 22, Score: 0.00000\n",
      "Feature: 23, Score: 0.00552\n",
      "Feature: 24, Score: 0.00448\n",
      "Feature: 25, Score: 0.00659\n",
      "Feature: 26, Score: 0.00430\n",
      "Feature: 27, Score: 0.00000\n",
      "Feature: 28, Score: 0.00000\n",
      "Feature: 29, Score: 0.00000\n",
      "Feature: 30, Score: 0.00122\n",
      "Feature: 31, Score: 0.00489\n",
      "Feature: 32, Score: 0.00000\n",
      "Feature: 33, Score: 0.01014\n",
      "Feature: 34, Score: 0.00000\n",
      "Feature: 35, Score: 0.00000\n",
      "Feature: 36, Score: 0.00000\n",
      "Feature: 37, Score: 0.00000\n",
      "Feature: 38, Score: 0.00425\n",
      "Feature: 39, Score: 0.00000\n",
      "Feature: 40, Score: 0.00258\n",
      "Feature: 41, Score: 0.00000\n",
      "Feature: 42, Score: 0.00000\n",
      "Feature: 43, Score: 0.00506\n",
      "Feature: 44, Score: 0.00000\n",
      "Feature: 45, Score: 0.00000\n",
      "Feature: 46, Score: 0.00000\n",
      "Feature: 47, Score: 0.00000\n",
      "Feature: 48, Score: 0.00000\n",
      "Feature: 49, Score: 0.00000\n",
      "Feature: 50, Score: 0.00000\n",
      "Feature: 51, Score: 0.00994\n",
      "Feature: 52, Score: 0.12342\n",
      "Feature: 53, Score: 0.07884\n",
      "Feature: 54, Score: 0.00000\n",
      "Feature: 55, Score: 0.00466\n",
      "Feature: 56, Score: 0.00000\n",
      "Feature: 57, Score: 0.00000\n",
      "Feature: 58, Score: 0.00000\n",
      "Feature: 59, Score: 0.00000\n",
      "Feature: 60, Score: 0.00864\n",
      "Feature: 61, Score: 0.00000\n",
      "Feature: 62, Score: 0.00000\n",
      "Feature: 63, Score: 0.00493\n",
      "Feature: 64, Score: 0.00233\n",
      "Feature: 65, Score: 0.00945\n",
      "Feature: 66, Score: 0.00102\n",
      "Feature: 67, Score: 0.00000\n",
      "Feature: 68, Score: 0.00359\n",
      "Feature: 69, Score: 0.00880\n",
      "Feature: 70, Score: 0.00000\n",
      "Feature: 71, Score: 0.00000\n",
      "Feature: 72, Score: 0.00000\n",
      "Feature: 73, Score: 0.00000\n",
      "Feature: 74, Score: 0.00000\n",
      "Feature: 75, Score: 0.00000\n",
      "Feature: 76, Score: 0.00000\n",
      "Feature: 77, Score: 0.00000\n",
      "Feature: 78, Score: 0.00000\n",
      "Feature: 79, Score: 0.00163\n",
      "Feature: 80, Score: 0.00647\n",
      "Feature: 81, Score: 0.26453\n",
      "Feature: 82, Score: 0.00000\n",
      "Feature: 83, Score: 0.00000\n",
      "Feature: 84, Score: 0.00000\n",
      "Feature: 85, Score: 0.01022\n",
      "Feature: 86, Score: 0.00000\n",
      "Feature: 87, Score: 0.00000\n",
      "Feature: 88, Score: 0.00000\n",
      "Feature: 89, Score: 0.00000\n",
      "Feature: 90, Score: 0.00000\n",
      "Feature: 91, Score: 0.00000\n",
      "Feature: 92, Score: 0.00000\n",
      "Feature: 93, Score: 0.00000\n",
      "Feature: 94, Score: 0.00000\n",
      "Feature: 95, Score: 0.00000\n",
      "Feature: 96, Score: 0.00000\n",
      "Feature: 97, Score: 0.00000\n",
      "Feature: 98, Score: 0.00000\n",
      "Feature: 99, Score: 0.00000\n",
      "Feature: 100, Score: 0.00461\n",
      "Feature: 101, Score: 0.00000\n",
      "Feature: 102, Score: 0.00403\n",
      "Feature: 103, Score: 0.00430\n",
      "Feature: 104, Score: 0.00000\n",
      "Feature: 105, Score: 0.00269\n",
      "Feature: 106, Score: 0.00000\n",
      "Feature: 107, Score: 0.00964\n",
      "Feature: 108, Score: 0.00000\n",
      "Feature: 109, Score: 0.00615\n",
      "Feature: 110, Score: 0.00000\n",
      "Feature: 111, Score: 0.00000\n",
      "Feature: 112, Score: 0.00000\n",
      "Feature: 113, Score: 0.00000\n",
      "Feature: 114, Score: 0.00849\n",
      "Feature: 115, Score: 0.00000\n",
      "Feature: 116, Score: 0.00000\n",
      "Feature: 117, Score: 0.00000\n",
      "Feature: 118, Score: 0.00417\n",
      "Feature: 119, Score: 0.00000\n",
      "Feature: 120, Score: 0.00269\n",
      "Feature: 121, Score: 0.00000\n",
      "Feature: 122, Score: 0.00000\n",
      "Feature: 123, Score: 0.00844\n",
      "Feature: 124, Score: 0.00000\n",
      "Feature: 125, Score: 0.00509\n",
      "Feature: 126, Score: 0.00000\n",
      "Feature: 127, Score: 0.00044\n",
      "Feature: 128, Score: 0.00034\n",
      "Feature: 129, Score: 0.00359\n",
      "Feature: 130, Score: 0.00000\n",
      "Feature: 131, Score: 0.00000\n",
      "Feature: 132, Score: 0.00000\n",
      "Feature: 133, Score: 0.00000\n",
      "Feature: 134, Score: 0.00225\n",
      "Feature: 135, Score: 0.00000\n",
      "Feature: 136, Score: 0.00000\n",
      "Feature: 137, Score: 0.00000\n",
      "Feature: 138, Score: 0.00000\n",
      "Feature: 139, Score: 0.00000\n",
      "Feature: 140, Score: 0.00000\n",
      "Feature: 141, Score: 0.00269\n",
      "Feature: 142, Score: 0.00000\n",
      "Feature: 143, Score: 0.00000\n",
      "Feature: 144, Score: 0.00000\n",
      "Feature: 145, Score: 0.00000\n",
      "Feature: 146, Score: 0.00000\n",
      "Feature: 147, Score: 0.00000\n",
      "Feature: 148, Score: 0.00000\n",
      "Feature: 149, Score: 0.00000\n",
      "Feature: 150, Score: 0.00000\n",
      "Feature: 151, Score: 0.00259\n",
      "Feature: 152, Score: 0.00101\n",
      "Feature: 153, Score: 0.00000\n",
      "Feature: 154, Score: 0.00000\n",
      "Feature: 155, Score: 0.00000\n",
      "Feature: 156, Score: 0.00000\n",
      "Feature: 157, Score: 0.00000\n",
      "Feature: 158, Score: 0.00000\n",
      "Feature: 159, Score: 0.00000\n",
      "Feature: 160, Score: 0.00000\n",
      "Feature: 161, Score: 0.00000\n",
      "Feature: 162, Score: 0.00062\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-73f0d55a0c86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Feature: %0d, Score: %.5f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# plot feature importance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
    "# use CART classification feature importance\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# define the model\n",
    "model = DecisionTreeClassifier()\n",
    "# fit the model\n",
    "model.fit(Xdumm, y)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.02714\n",
      "Feature: 1, Score: 0.02313\n",
      "Feature: 2, Score: 0.02862\n",
      "Feature: 3, Score: 0.00710\n",
      "Feature: 4, Score: 0.02615\n",
      "Feature: 5, Score: 0.00973\n",
      "Feature: 6, Score: 0.03022\n",
      "Feature: 7, Score: 0.01592\n",
      "Feature: 8, Score: 0.01637\n",
      "Feature: 9, Score: 0.02130\n",
      "Feature: 10, Score: 0.00695\n",
      "Feature: 11, Score: 0.00770\n",
      "Feature: 12, Score: 0.01055\n",
      "Feature: 13, Score: 0.02377\n",
      "Feature: 14, Score: 0.02801\n",
      "Feature: 15, Score: 0.03070\n",
      "Feature: 16, Score: 0.03349\n",
      "Feature: 17, Score: 0.02147\n",
      "Feature: 18, Score: 0.00677\n",
      "Feature: 19, Score: 0.00623\n",
      "Feature: 20, Score: 0.02415\n",
      "Feature: 21, Score: 0.00389\n",
      "Feature: 22, Score: 0.00374\n",
      "Feature: 23, Score: 0.00404\n",
      "Feature: 24, Score: 0.00468\n",
      "Feature: 25, Score: 0.00409\n",
      "Feature: 26, Score: 0.00367\n",
      "Feature: 27, Score: 0.00268\n",
      "Feature: 28, Score: 0.00428\n",
      "Feature: 29, Score: 0.00333\n",
      "Feature: 30, Score: 0.00298\n",
      "Feature: 31, Score: 0.00385\n",
      "Feature: 32, Score: 0.00308\n",
      "Feature: 33, Score: 0.00127\n",
      "Feature: 34, Score: 0.00238\n",
      "Feature: 35, Score: 0.00219\n",
      "Feature: 36, Score: 0.00490\n",
      "Feature: 37, Score: 0.00217\n",
      "Feature: 38, Score: 0.00369\n",
      "Feature: 39, Score: 0.00261\n",
      "Feature: 40, Score: 0.00236\n",
      "Feature: 41, Score: 0.00238\n",
      "Feature: 42, Score: 0.00223\n",
      "Feature: 43, Score: 0.00099\n",
      "Feature: 44, Score: 0.00266\n",
      "Feature: 45, Score: 0.00361\n",
      "Feature: 46, Score: 0.00239\n",
      "Feature: 47, Score: 0.00210\n",
      "Feature: 48, Score: 0.00126\n",
      "Feature: 49, Score: 0.00232\n",
      "Feature: 50, Score: 0.00147\n",
      "Feature: 51, Score: 0.00304\n",
      "Feature: 52, Score: 0.05146\n",
      "Feature: 53, Score: 0.02430\n",
      "Feature: 54, Score: 0.00076\n",
      "Feature: 55, Score: 0.00128\n",
      "Feature: 56, Score: 0.00279\n",
      "Feature: 57, Score: 0.00152\n",
      "Feature: 58, Score: 0.00168\n",
      "Feature: 59, Score: 0.00155\n",
      "Feature: 60, Score: 0.00215\n",
      "Feature: 61, Score: 0.00202\n",
      "Feature: 62, Score: 0.00233\n",
      "Feature: 63, Score: 0.00159\n",
      "Feature: 64, Score: 0.00150\n",
      "Feature: 65, Score: 0.00106\n",
      "Feature: 66, Score: 0.00279\n",
      "Feature: 67, Score: 0.00310\n",
      "Feature: 68, Score: 0.00394\n",
      "Feature: 69, Score: 0.00438\n",
      "Feature: 70, Score: 0.00409\n",
      "Feature: 71, Score: 0.00394\n",
      "Feature: 72, Score: 0.00341\n",
      "Feature: 73, Score: 0.00422\n",
      "Feature: 74, Score: 0.00097\n",
      "Feature: 75, Score: 0.00436\n",
      "Feature: 76, Score: 0.00178\n",
      "Feature: 77, Score: 0.00428\n",
      "Feature: 78, Score: 0.00384\n",
      "Feature: 79, Score: 0.00488\n",
      "Feature: 80, Score: 0.00362\n",
      "Feature: 81, Score: 0.11509\n",
      "Feature: 82, Score: 0.03417\n",
      "Feature: 83, Score: 0.02829\n",
      "Feature: 84, Score: 0.00232\n",
      "Feature: 85, Score: 0.00333\n",
      "Feature: 86, Score: 0.00373\n",
      "Feature: 87, Score: 0.00237\n",
      "Feature: 88, Score: 0.00506\n",
      "Feature: 89, Score: 0.00370\n",
      "Feature: 90, Score: 0.00435\n",
      "Feature: 91, Score: 0.00384\n",
      "Feature: 92, Score: 0.00243\n",
      "Feature: 93, Score: 0.00204\n",
      "Feature: 94, Score: 0.00483\n",
      "Feature: 95, Score: 0.00261\n",
      "Feature: 96, Score: 0.00462\n",
      "Feature: 97, Score: 0.00440\n",
      "Feature: 98, Score: 0.00267\n",
      "Feature: 99, Score: 0.00254\n",
      "Feature: 100, Score: 0.00377\n",
      "Feature: 101, Score: 0.00312\n",
      "Feature: 102, Score: 0.00298\n",
      "Feature: 103, Score: 0.00262\n",
      "Feature: 104, Score: 0.00523\n",
      "Feature: 105, Score: 0.00519\n",
      "Feature: 106, Score: 0.00298\n",
      "Feature: 107, Score: 0.00478\n",
      "Feature: 108, Score: 0.00401\n",
      "Feature: 109, Score: 0.00349\n",
      "Feature: 110, Score: 0.00161\n",
      "Feature: 111, Score: 0.00222\n",
      "Feature: 112, Score: 0.00170\n",
      "Feature: 113, Score: 0.00192\n",
      "Feature: 114, Score: 0.00252\n",
      "Feature: 115, Score: 0.00234\n",
      "Feature: 116, Score: 0.00161\n",
      "Feature: 117, Score: 0.00217\n",
      "Feature: 118, Score: 0.00216\n",
      "Feature: 119, Score: 0.00140\n",
      "Feature: 120, Score: 0.00273\n",
      "Feature: 121, Score: 0.00244\n",
      "Feature: 122, Score: 0.00154\n",
      "Feature: 123, Score: 0.00232\n",
      "Feature: 124, Score: 0.00037\n",
      "Feature: 125, Score: 0.00229\n",
      "Feature: 126, Score: 0.00118\n",
      "Feature: 127, Score: 0.00102\n",
      "Feature: 128, Score: 0.00150\n",
      "Feature: 129, Score: 0.00217\n",
      "Feature: 130, Score: 0.00052\n",
      "Feature: 131, Score: 0.00161\n",
      "Feature: 132, Score: 0.00076\n",
      "Feature: 133, Score: 0.00098\n",
      "Feature: 134, Score: 0.00250\n",
      "Feature: 135, Score: 0.00082\n",
      "Feature: 136, Score: 0.00153\n",
      "Feature: 137, Score: 0.00171\n",
      "Feature: 138, Score: 0.00206\n",
      "Feature: 139, Score: 0.00182\n",
      "Feature: 140, Score: 0.00104\n",
      "Feature: 141, Score: 0.00119\n",
      "Feature: 142, Score: 0.00116\n",
      "Feature: 143, Score: 0.00120\n",
      "Feature: 144, Score: 0.00252\n",
      "Feature: 145, Score: 0.00070\n",
      "Feature: 146, Score: 0.00087\n",
      "Feature: 147, Score: 0.00194\n",
      "Feature: 148, Score: 0.00183\n",
      "Feature: 149, Score: 0.00146\n",
      "Feature: 150, Score: 0.00090\n",
      "Feature: 151, Score: 0.00121\n",
      "Feature: 152, Score: 0.00176\n",
      "Feature: 153, Score: 0.00221\n",
      "Feature: 154, Score: 0.00271\n",
      "Feature: 155, Score: 0.00020\n",
      "Feature: 156, Score: 0.00185\n",
      "Feature: 157, Score: 0.00083\n",
      "Feature: 158, Score: 0.00181\n",
      "Feature: 159, Score: 0.00041\n",
      "Feature: 160, Score: 0.00147\n",
      "Feature: 161, Score: 0.00136\n",
      "Feature: 162, Score: 0.00187\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-eeffa1d23650>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Feature: %0d, Score: %.5f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# plot feature importance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimportance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# use random forest feature importance\n",
    "# This approach can also be used with the bagging and extra trees algorithms.\n",
    "# https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# define the model\n",
    "model = RandomForestClassifier()\n",
    "# fit the model\n",
    "model.fit(Xdumm, y)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score for estimator 0:\n",
      "                                importance\n",
      "incident_severity_Major Damage    0.156566\n",
      "insured_hobbies_chess             0.049119\n",
      "months_as_customer                0.035151\n",
      "incident_severity_Total Loss      0.033092\n",
      "property_claim                    0.032555\n",
      "incident_severity_Minor Damage    0.030792\n",
      "injury_claim                      0.029776\n",
      "insured_zip                       0.029532\n",
      "vehicle_claim                     0.028932\n",
      "months_bf_incident                0.027750\n",
      "total_claim_amount                0.024879\n",
      "age                               0.023256\n",
      "insured_hobbies_cross-fit         0.020396\n",
      "incident_hour_of_the_day          0.019590\n",
      "policy_number                     0.018939\n",
      "policy_annual_premium             0.018659\n",
      "policy_deductable                 0.017052\n",
      "witnesses                         0.015292\n",
      "auto_year                         0.014910\n",
      "capital_loss                      0.014299\n",
      "Features sorted by their score for estimator 1:\n",
      "                                importance\n",
      "incident_severity_Major Damage    0.076858\n",
      "property_claim                    0.048967\n",
      "incident_hour_of_the_day          0.042327\n",
      "vehicle_claim                     0.040818\n",
      "insured_zip                       0.036180\n",
      "incident_severity_Minor Damage    0.034374\n",
      "injury_claim                      0.029813\n",
      "incident_severity_Total Loss      0.029432\n",
      "policy_number                     0.029310\n",
      "insured_hobbies_cross-fit         0.028634\n",
      "months_bf_incident                0.028301\n",
      "capital_gains                     0.025910\n",
      "policy_annual_premium             0.025058\n",
      "age                               0.019223\n",
      "months_as_customer                0.018040\n",
      "capital_loss                      0.017389\n",
      "total_claim_amount                0.017031\n",
      "auto_year                         0.014394\n",
      "insured_hobbies_chess             0.013718\n",
      "incident_state_SC                 0.012897\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/55466081/how-to-calculate-feature-importance-in-each-models-of-cross-validation-in-sklear\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators =10, random_state = 42, class_weight=\"balanced\")\n",
    "output = cross_validate(clf, Xdumm, y, cv=2, scoring = 'accuracy', return_estimator =True)\n",
    "for idx,estimator in enumerate(output['estimator']):\n",
    "    print(\"Features sorted by their score for estimator {}:\".format(idx))\n",
    "    feature_importances = pd.DataFrame(estimator.feature_importances_,\n",
    "                                       index = Xdumm.columns,\n",
    "                                        columns=['importance']).sort_values('importance', ascending=False)\n",
    "    print(feature_importances.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
