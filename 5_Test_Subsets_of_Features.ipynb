{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Insurance Claim Fraud Indicators and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mary Donovan Martello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goal of this project was to identify significant features in fraudulent insurance claim transactions and to design predictive classification models to predict whether fraud was reported on the insurance claim transaction. This notebook tests different subsets of input features to see which subset(s) may produce the best results in the predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Test Different Subsets of Input Features for Optimizing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset includes 1,000 prior claim transaction records.  Each record has a mix of 38 quantitative and categorical data features about the claim filed, including information on the policy, insured, and automobile, aspects of the damage incident, and elements of the claim filed.  The dataset also has a feature that indicates whether fraud was reported on each observation (i.e., either Y or N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfClaims = pd.read_csv('FradulentInsuranceClaims.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "      <th>_c39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014-10-17           OH   \n",
       "1                 228   42         342868       2006-06-27           IN   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "\n",
       "   insured_zip  ... police_report_available total_claim_amount injury_claim  \\\n",
       "0       466132  ...                     YES              71610         6510   \n",
       "1       468176  ...                       ?               5070          780   \n",
       "\n",
       "  property_claim vehicle_claim  auto_make  auto_model auto_year  \\\n",
       "0          13020         52080       Saab         92x      2004   \n",
       "1            780          3510   Mercedes        E400      2007   \n",
       "\n",
       "  fraud_reported _c39  \n",
       "0              Y  NaN  \n",
       "1              Y  NaN  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfClaims.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset includes the original data that was cleaned, prepared, and transformed into Principal Component features in the 1_EDA_Prep notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scaled, transformed and PCA df\n",
    "pcaDF = pd.read_csv('pcaClaimsLog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  ## Phase 2: Create Subsets to See if it Improves Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trave\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# import libraries for models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "import yellowbrick\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#stop unnecessary warnings from printing to the screen\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare feature matrix and target vector for creating subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use to test 'auto_year'\n",
    "ordf = pd.read_csv('FradulentInsuranceClaims.csv')\n",
    "# only use to test 'auto_year'\n",
    "pcaDF['auto_year'] = ordf['auto_year']\n",
    "\n",
    "#get the categorical data\n",
    "cat_features = ['policy_state', 'auto_year',\n",
    "       'insured_sex', 'insured_education_level', 'insured_occupation', 'insured_hobbies',\n",
    "       'insured_relationship', 'incident_type', 'collision_type',\n",
    "       'incident_severity', 'authorities_contacted', 'incident_state',\n",
    "       'incident_city', 'property_damage', 'police_report_available',\n",
    "       'auto_make', 'auto_model']\n",
    "\n",
    "df_cat2 = pcaDF[cat_features]\n",
    "\n",
    "# One Hot Encoding \n",
    "dfDumm2 = pd.get_dummies(df_cat2)\n",
    "\n",
    "# create a whole features dataset that can be used for train and validation data splitting\n",
    "# here we will combine the numerical features and the dummie features together\n",
    "dfNum2 = pcaDF.drop(['policy_state', 'auto_year',\n",
    "       'insured_sex', 'insured_education_level', 'insured_occupation', 'insured_hobbies',\n",
    "       'insured_relationship', 'incident_type', 'collision_type',\n",
    "       'incident_severity', 'authorities_contacted', 'incident_state',\n",
    "       'incident_city', 'property_damage', 'police_report_available',\n",
    "       'auto_make', 'auto_model'], axis = 1)\n",
    "Xdumm2 = pd.concat([dfNum2, dfDumm2], axis=1)\n",
    "# create a whole target dataset that can be used for train and validation data splitting\n",
    "y2 =  pcaDF['fraud_reported']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Baseline Model again with Subset Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.33\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# RF top 5\n",
    "subset1 = Xdumm2.loc[:, [\n",
    " 'incident_severity_Major Damage',\n",
    " 'insured_hobbies_chess',\n",
    " 'PC13',\n",
    " 'PC11',\n",
    " 'PC9']]\n",
    "\n",
    "# separate data into training and validation \n",
    "S1Train, S1Test, yTrain_S1, yTest_S1 = train_test_split(subset1, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS1 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS1.fit(S1Train, yTrain_S1)\n",
    "\n",
    "# predict on test set\n",
    "yhatS1 = modelLRS1.predict(S1Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S1, yhatS1)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.33\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# RF top 2\n",
    "subset2 = Xdumm2.loc[:, [\n",
    " 'incident_severity_Major Damage',\n",
    " 'insured_hobbies_chess'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S2Train, S2Test, yTrain_S2, yTest_S2 = train_test_split(subset2, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS2 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS2.fit(S2Train, yTrain_S2)\n",
    "\n",
    "# predict on test set\n",
    "yhatS2 = modelLRS2.predict(S2Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S2, yhatS2)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.33\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# incident_severity_Major Damage only\n",
    "subset3 = Xdumm2.loc[:, [\n",
    " 'incident_severity_Major Damage'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S3Train, S3Test, yTrain_S3, yTest_S3 = train_test_split(subset3, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS3 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS3.fit(S3Train, yTrain_S3)\n",
    "\n",
    "# predict on test set\n",
    "yhatS3 = modelLRS3.predict(S3Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S3, yhatS3)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.33\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# incident_severity_Major Damage and Witnesses only\n",
    "subset4 = Xdumm2.loc[:, [\n",
    " 'incident_severity_Major Damage',\n",
    " 'PC9'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S4Train, S4Test, yTrain_S4, yTest_S4 = train_test_split(subset4, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS4 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS4.fit(S4Train, yTrain_S4)\n",
    "\n",
    "# predict on test set\n",
    "yhatS4 = modelLRS4.predict(S4Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S4, yhatS4)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.33\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# incident_severity_Major Damage, auto_year, and Witnesses only\n",
    "subset5 = Xdumm2.loc[:, [\n",
    " 'incident_severity_Major Damage',\n",
    " 'PC9', 'auto_year'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S5Train, S5Test, yTrain_S5, yTest_S5 = train_test_split(subset5, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS5 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS5.fit(S5Train, yTrain_S5)\n",
    "\n",
    "# predict on test set\n",
    "yhatS5 = modelLRS5.predict(S5Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S5, yhatS5)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.00\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# RF with .02 or greater\n",
    "subset6 = Xdumm2.loc[:, [\n",
    " 'incident_severity_Major Damage',\n",
    " 'insured_hobbies_chess',\n",
    " 'PC13',\n",
    " 'PC11',\n",
    " 'PC9', 'PC16', 'incident_severity_Minor Damage', 'PC14', 'PC7', 'PC10', 'insured_hobbies_cross-fit',\n",
    "    'PC15', 'PC2', 'PC6', 'PC5', 'PC8', 'PC12', 'PC1', 'PC4', 'PC3',  'incident_severity_Total Loss'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S6Train, S6Test, yTrain_S6, yTest_S6 = train_test_split(subset6, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS6 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS6.fit(S6Train, yTrain_S6)\n",
    "\n",
    "# predict on test set\n",
    "yhatS6 = modelLRS6.predict(S6Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S6, yhatS6)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.33\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# CART with .01 or greater\n",
    "subset7 = Xdumm2.loc[:, [\n",
    " 'incident_severity_Major Damage',\n",
    " 'insured_hobbies_chess',\n",
    " 'PC13',\n",
    " 'PC11',\n",
    " 'PC9', 'PC16', 'PC14', 'PC7', 'PC10', 'insured_hobbies_cross-fit',\n",
    "    'PC2', 'PC6', 'PC5', 'PC12', 'PC1', 'PC4', 'PC3',  'insured_occupation_tech-support',\n",
    "     'insured_relationship_not-in-family'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S7Train, S7Test, yTrain_S7, yTest_S7 = train_test_split(subset7, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS7 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS7.fit(S7Train, yTrain_S7)\n",
    "\n",
    "# predict on test set\n",
    "yhatS7 = modelLRS7.predict(S7Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S7, yhatS7)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.00\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# CART with .02 or greater\n",
    "subset8 = Xdumm2.loc[:, [\n",
    " 'incident_severity_Major Damage',\n",
    " 'insured_hobbies_chess',\n",
    " 'PC13',\n",
    " 'PC11',\n",
    " 'PC9', 'PC10', 'insured_hobbies_cross-fit',\n",
    "    'PC5', 'PC12', 'PC1', 'PC4', 'PC3'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S8Train, S8Test, yTrain_S8, yTest_S8 = train_test_split(subset8, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS8 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS8.fit(S8Train, yTrain_S8)\n",
    "\n",
    "# predict on test set\n",
    "yhatS8 = modelLRS8.predict(S8Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S8, yhatS8)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.67\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# CART with TOP 6 / .03 or greater\n",
    "subset9 = Xdumm2.loc[:, [\n",
    " 'incident_severity_Major Damage',\n",
    " 'insured_hobbies_chess',\n",
    " 'PC13',\n",
    " 'PC5',\n",
    " 'PC9', 'insured_hobbies_cross-fit'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S9Train, S9Test, yTrain_S9, yTest_S9 = train_test_split(subset9, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS9 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS9.fit(S9Train, yTrain_S9)\n",
    "\n",
    "# predict on test set\n",
    "yhatS9 = modelLRS9.predict(S9Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S9, yhatS9)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.33\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# CART with TOP 4 / .07 or greater\n",
    "subset10 = Xdumm2.loc[:, [\n",
    " 'incident_severity_Major Damage',\n",
    " 'insured_hobbies_chess',\n",
    " 'PC9', 'insured_hobbies_cross-fit'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S10Train, S10Test, yTrain_S10, yTest_S10 = train_test_split(subset10, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS10 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS10.fit(S10Train, yTrain_S10)\n",
    "\n",
    "# predict on test set\n",
    "yhatS10 = modelLRS10.predict(S10Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S10, yhatS10)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.33\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# CART with TOP 3 / .08 or greater\n",
    "subset11 = Xdumm2.loc[:, [\n",
    " 'incident_severity_Major Damage',\n",
    " 'insured_hobbies_chess',\n",
    " 'PC9'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S11Train, S11Test, yTrain_S11, yTest_S11 = train_test_split(subset11, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS11 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS11.fit(S11Train, yTrain_S11)\n",
    "\n",
    "# predict on test set\n",
    "yhatS11 = modelLRS11.predict(S11Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S11, yhatS11)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.33\n"
     ]
    }
   ],
   "source": [
    "# create a subset of the df that can be used for model evalutation\n",
    "# Coeff top 4\n",
    "subset12 = Xdumm2.loc[:, [\n",
    " 'incident_severity_Major Damage',\n",
    " 'insured_hobbies_chess',\n",
    "  'insured_relationship_not-in-family', 'insured_hobbies_cross-fit'\n",
    " ]]\n",
    "\n",
    "# separate data into training and validation \n",
    "S12Train, S12Test, yTrain_S12, yTest_S12 = train_test_split(subset12, y2, test_size =0.3, random_state=11)\n",
    "\n",
    "# Instantiate the logistic regression model using default parameters\n",
    "modelLRS12 = LogisticRegression()\n",
    "\n",
    "# Fit the model with training data\n",
    "modelLRS12.fit(S12Train, yTrain_S12)\n",
    "\n",
    "# predict on test set\n",
    "yhatS12 = modelLRS12.predict(S12Test)\n",
    "\n",
    "# evaluate the baseline with accuracy score\n",
    "accuracy = accuracy_score(yTest_S12, yhatS12)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
