{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Insurance Claim Fraud Indicators and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mary Donovan Martello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The goal of this project was to identify significant features in fraudulent insurance claim transactions and to design predictive classification models to predict whether fraud was reported on the insurance claim transaction.  This notebook includes exploratory data analysis and data preparation for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1:  Exploratory Data Analysis and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data set and libraries for data preparation phase\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# importing regex module (search strings) RegEx can be used to check if a string contains the specified search pattern\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset includes 1,000 prior claim transaction records.  Each record has a mix of 38 quantitative and categorical data features about the claim filed, including information on the policy, insured, and automobile, aspects of the damage incident, and elements of the claim filed.  The dataset also has a feature that indicates whether fraud was reported on each observation (i.e., either Y or N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfClaims = pd.read_csv('FradulentInsuranceClaims.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "      <th>_c39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014-10-17           OH   \n",
       "1                 228   42         342868       2006-06-27           IN   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "\n",
       "   insured_zip  ... police_report_available total_claim_amount injury_claim  \\\n",
       "0       466132  ...                     YES              71610         6510   \n",
       "1       468176  ...                       ?               5070          780   \n",
       "\n",
       "  property_claim vehicle_claim  auto_make  auto_model auto_year  \\\n",
       "0          13020         52080       Saab         92x      2004   \n",
       "1            780          3510   Mercedes        E400      2007   \n",
       "\n",
       "  fraud_reported _c39  \n",
       "0              Y  NaN  \n",
       "1              Y  NaN  \n",
       "\n",
       "[2 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfClaims.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the column names\n",
    "dfClaims.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['months_as_customer', 'age', 'policy_number', 'policy_bind_date',\n",
       "       'policy_state', 'policy_csl', 'policy_deductable',\n",
       "       'policy_annual_premium', 'umbrella_limit', 'insured_zip', 'insured_sex',\n",
       "       'insured_education_level', 'insured_occupation', 'insured_hobbies',\n",
       "       'insured_relationship', 'capital_gains', 'capital_loss',\n",
       "       'incident_date', 'incident_type', 'collision_type', 'incident_severity',\n",
       "       'authorities_contacted', 'incident_state', 'incident_city',\n",
       "       'incident_location', 'incident_hour_of_the_day',\n",
       "       'number_of_vehicles_involved', 'property_damage', 'bodily_injuries',\n",
       "       'witnesses', 'police_report_available', 'total_claim_amount',\n",
       "       'injury_claim', 'property_claim', 'vehicle_claim', 'auto_make',\n",
       "       'auto_model', 'auto_year', 'fraud_reported', '_c39'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename difficult column names\n",
    "dfClaims.rename(columns={'capital-gains': 'capital_gains', 'capital-loss': 'capital_loss'}, inplace=True)\n",
    "dfClaims.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "months_as_customer             False\n",
       "age                            False\n",
       "policy_number                  False\n",
       "policy_bind_date               False\n",
       "policy_state                   False\n",
       "policy_csl                     False\n",
       "policy_deductable              False\n",
       "policy_annual_premium          False\n",
       "umbrella_limit                 False\n",
       "insured_zip                    False\n",
       "insured_sex                    False\n",
       "insured_education_level        False\n",
       "insured_occupation             False\n",
       "insured_hobbies                False\n",
       "insured_relationship           False\n",
       "capital_gains                  False\n",
       "capital_loss                   False\n",
       "incident_date                  False\n",
       "incident_type                  False\n",
       "collision_type                  True\n",
       "incident_severity              False\n",
       "authorities_contacted          False\n",
       "incident_state                 False\n",
       "incident_city                  False\n",
       "incident_location              False\n",
       "incident_hour_of_the_day       False\n",
       "number_of_vehicles_involved    False\n",
       "property_damage                 True\n",
       "bodily_injuries                False\n",
       "witnesses                      False\n",
       "police_report_available         True\n",
       "total_claim_amount             False\n",
       "injury_claim                   False\n",
       "property_claim                 False\n",
       "vehicle_claim                  False\n",
       "auto_make                      False\n",
       "auto_model                     False\n",
       "auto_year                      False\n",
       "fraud_reported                 False\n",
       "_c39                            True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether the data has any null values \n",
    "\n",
    "# There are '?' in the datset which are removed by NaN Values\n",
    "dfClaims = dfClaims.replace('?',np.NaN)\n",
    "\n",
    "dfClaims.isnull().any()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 40)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check df shape\n",
    "dfClaims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which rows have null values\n",
    "is_NaN = dfClaims.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = dfClaims[row_has_NaN]\n",
    "\n",
    "#print(rows_with_NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are '?\" in three features; address these using fillna\n",
    "\n",
    "# replace the '?' by the most common collision type \n",
    "dfClaims['collision_type'].fillna(dfClaims['collision_type'].mode()[0], inplace = True)\n",
    "\n",
    "# property damage is either yes or no; fill with no because non responses for property damage might mean no property damage.\n",
    "dfClaims['property_damage'].fillna('NO', inplace = True)\n",
    "\n",
    "# again, if there are no responses for police report available it may mean No report available\n",
    "dfClaims['police_report_available'].fillna('NO', inplace = True)\n",
    "\n",
    "dfClaims.isnull().any().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "months_as_customer             False\n",
       "age                            False\n",
       "policy_number                  False\n",
       "policy_bind_date               False\n",
       "policy_state                   False\n",
       "policy_csl                     False\n",
       "policy_deductable              False\n",
       "policy_annual_premium          False\n",
       "umbrella_limit                 False\n",
       "insured_zip                    False\n",
       "insured_sex                    False\n",
       "insured_education_level        False\n",
       "insured_occupation             False\n",
       "insured_hobbies                False\n",
       "insured_relationship           False\n",
       "capital_gains                  False\n",
       "capital_loss                   False\n",
       "incident_date                  False\n",
       "incident_type                  False\n",
       "collision_type                 False\n",
       "incident_severity              False\n",
       "authorities_contacted          False\n",
       "incident_state                 False\n",
       "incident_city                  False\n",
       "incident_location              False\n",
       "incident_hour_of_the_day       False\n",
       "number_of_vehicles_involved    False\n",
       "property_damage                False\n",
       "bodily_injuries                False\n",
       "witnesses                      False\n",
       "police_report_available        False\n",
       "total_claim_amount             False\n",
       "injury_claim                   False\n",
       "property_claim                 False\n",
       "vehicle_claim                  False\n",
       "auto_make                      False\n",
       "auto_model                     False\n",
       "auto_year                      False\n",
       "fraud_reported                 False\n",
       "_c39                            True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which features have null values?\n",
    "dfClaims.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing null values to avoid errors: the _c39 feature is all null values\n",
    "dfClaims.dropna(axis='columns', thresh=100, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that all null values have been removed\n",
    "dfClaims.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rear Collision     470\n",
       "Side Collision     276\n",
       "Front Collision    254\n",
       "Name: collision_type, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm ?s replaced:  were 177 ?\n",
    "dfClaims['collision_type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO     698\n",
       "YES    302\n",
       "Name: property_damage, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm ?s replaced:  were 360 ?\n",
    "dfClaims['property_damage'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO     686\n",
       "YES    314\n",
       "Name: police_report_available, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm ?s replaced:  were 342 ?\n",
    "dfClaims['police_report_available'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    753\n",
       "Y    247\n",
       "Name: fraud_reported, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fraud counts\n",
    "dfClaims.fraud_reported.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['months_as_customer', 'age', 'policy_number', 'policy_bind_date',\n",
       "       'policy_state', 'policy_deductable', 'policy_annual_premium',\n",
       "       'umbrella_limit', 'insured_zip', 'insured_sex',\n",
       "       'insured_education_level', 'insured_occupation', 'insured_hobbies',\n",
       "       'insured_relationship', 'capital_gains', 'capital_loss',\n",
       "       'incident_date', 'incident_type', 'collision_type', 'incident_severity',\n",
       "       'authorities_contacted', 'incident_state', 'incident_city',\n",
       "       'incident_location', 'incident_hour_of_the_day',\n",
       "       'number_of_vehicles_involved', 'property_damage', 'bodily_injuries',\n",
       "       'witnesses', 'police_report_available', 'total_claim_amount',\n",
       "       'injury_claim', 'property_claim', 'vehicle_claim', 'auto_make',\n",
       "       'auto_model', 'auto_year', 'fraud_reported', 'csl_bodily', 'csl_prop'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split policy_csl into separate columns as it has two values per column\n",
    "\n",
    "# new data frame with split value columns \n",
    "newDF = dfClaims[\"policy_csl\"].str.split(\"/\", n = 1, expand = True)\n",
    "\n",
    "# making separate csl_bodily column from new data frame \n",
    "dfClaims[\"csl_bodily\"] = newDF[0] \n",
    "  \n",
    "# making separate csl_property column from new data frame \n",
    "dfClaims[\"csl_prop\"] = newDF[1] \n",
    "  \n",
    "# Dropping old policy_csl columns \n",
    "dfClaims.drop(columns =[\"policy_csl\"], inplace = True) \n",
    "\n",
    "# convert from string to int\n",
    "dfClaims[\"csl_bodily\"] = dfClaims[\"csl_bodily\"].astype(int)\n",
    "dfClaims[\"csl_prop\"] = dfClaims[\"csl_prop\"].astype(int)\n",
    "\n",
    "# df display \n",
    "dfClaims.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 40)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape again\n",
    "dfClaims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 40)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop umbrella outlier observation\n",
    "dfClaims.drop(dfClaims[dfClaims['umbrella_limit'] < 0].index, inplace = True)\n",
    "dfClaims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create derived feature for length of time claimant was a customer before claim incident.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 999 entries, 0 to 999\n",
      "Data columns (total 40 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   months_as_customer           999 non-null    int64         \n",
      " 1   age                          999 non-null    int64         \n",
      " 2   policy_number                999 non-null    int64         \n",
      " 3   policy_bind_date             999 non-null    datetime64[ns]\n",
      " 4   policy_state                 999 non-null    object        \n",
      " 5   policy_deductable            999 non-null    int64         \n",
      " 6   policy_annual_premium        999 non-null    float64       \n",
      " 7   umbrella_limit               999 non-null    int64         \n",
      " 8   insured_zip                  999 non-null    int64         \n",
      " 9   insured_sex                  999 non-null    object        \n",
      " 10  insured_education_level      999 non-null    object        \n",
      " 11  insured_occupation           999 non-null    object        \n",
      " 12  insured_hobbies              999 non-null    object        \n",
      " 13  insured_relationship         999 non-null    object        \n",
      " 14  capital_gains                999 non-null    int64         \n",
      " 15  capital_loss                 999 non-null    int64         \n",
      " 16  incident_date                999 non-null    datetime64[ns]\n",
      " 17  incident_type                999 non-null    object        \n",
      " 18  collision_type               999 non-null    object        \n",
      " 19  incident_severity            999 non-null    object        \n",
      " 20  authorities_contacted        999 non-null    object        \n",
      " 21  incident_state               999 non-null    object        \n",
      " 22  incident_city                999 non-null    object        \n",
      " 23  incident_location            999 non-null    object        \n",
      " 24  incident_hour_of_the_day     999 non-null    int64         \n",
      " 25  number_of_vehicles_involved  999 non-null    int64         \n",
      " 26  property_damage              999 non-null    object        \n",
      " 27  bodily_injuries              999 non-null    int64         \n",
      " 28  witnesses                    999 non-null    int64         \n",
      " 29  police_report_available      999 non-null    object        \n",
      " 30  total_claim_amount           999 non-null    int64         \n",
      " 31  injury_claim                 999 non-null    int64         \n",
      " 32  property_claim               999 non-null    int64         \n",
      " 33  vehicle_claim                999 non-null    int64         \n",
      " 34  auto_make                    999 non-null    object        \n",
      " 35  auto_model                   999 non-null    object        \n",
      " 36  auto_year                    999 non-null    int64         \n",
      " 37  fraud_reported               999 non-null    object        \n",
      " 38  csl_bodily                   999 non-null    int32         \n",
      " 39  csl_prop                     999 non-null    int32         \n",
      "dtypes: datetime64[ns](2), float64(1), int32(2), int64(17), object(18)\n",
      "memory usage: 312.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# overwriting data after changing date format \n",
    "dfClaims[\"incident_date\"]= pd.to_datetime(dfClaims[\"incident_date\"])\n",
    "dfClaims[\"policy_bind_date\"]= pd.to_datetime(dfClaims[\"policy_bind_date\"])\n",
    "dfClaims.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3\n",
       "1      102\n",
       "2      173\n",
       "3      295\n",
       "4        8\n",
       "      ... \n",
       "995    283\n",
       "996     12\n",
       "997    143\n",
       "998     39\n",
       "999    219\n",
       "Name: months_bf_incident, Length: 999, dtype: int32"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new column for diff in months between policy_bind_date and incident_date\n",
    "dfClaims['months_bf_incident'] = ((dfClaims.incident_date - dfClaims.policy_bind_date)/np.timedelta64(1, 'M'))\n",
    "dfClaims['months_bf_incident'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping old date coluns \n",
    "dfClaims.drop(columns =[\"policy_bind_date\", \"incident_date\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['months_as_customer', 'age', 'policy_number', 'policy_state',\n",
       "       'policy_deductable', 'policy_annual_premium', 'umbrella_limit',\n",
       "       'insured_zip', 'insured_sex', 'insured_education_level',\n",
       "       'insured_occupation', 'insured_hobbies', 'insured_relationship',\n",
       "       'capital_gains', 'capital_loss', 'incident_type', 'collision_type',\n",
       "       'incident_severity', 'authorities_contacted', 'incident_state',\n",
       "       'incident_city', 'incident_location', 'incident_hour_of_the_day',\n",
       "       'number_of_vehicles_involved', 'property_damage', 'bodily_injuries',\n",
       "       'witnesses', 'police_report_available', 'total_claim_amount',\n",
       "       'injury_claim', 'property_claim', 'vehicle_claim', 'auto_make',\n",
       "       'auto_model', 'auto_year', 'fraud_reported', 'csl_bodily', 'csl_prop',\n",
       "       'months_bf_incident'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm columns\n",
    "dfClaims.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 39)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm shape\n",
    "dfClaims.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This project utilized the EDA from this Exploratory Data Analysis and Hypothesis Testing project: [EDA.](https://github.com/MaryDonovanMartello/EDA-and-Hypothesis-Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataset with quantitative variables (exlcluding ones with too many nonunique values to be helpful)\n",
    "dfClaims_quantVars = dfClaims.filter(['months_as_customer', 'age', 'policy_deductable', 'policy_annual_premium', 'umbrella_limit', 'capital_gains', 'capital_loss', 'incident_hour_of_the_day', 'number_of_vehicles_involved', 'bodily_injuries', 'witnesses', 'total_claim_amount', 'injury_claim', 'property_claim', 'vehicle_claim', 'auto_year', 'csl_bodily', 'csl_prop'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 18)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfClaims_quantVars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This project utilized visuals from the 2_R_Visuals file and the EDA from this Exploratory Data Analysis and Hypothesis Testing project:*** [EDA.](https://github.com/MaryDonovanMartello/EDA-and-Hypothesis-Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries for statistical exploratory analysis\n",
    "from collections import Counter\n",
    "import random\n",
    "import scipy.stats\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats\n",
    "import patsy #stats\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Each record in the dataset includes a label of whether the claim was classified as fraudulent (fraud = Y) or as non-fraudulent (fraud = N). Create separate subsets of the dataset so that one subset only has records that did not have fraud transactions and another subset that only has records with fraud transactions. Use these separate subsets for EDA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset for fraud reported if yes\n",
    "rowsYesFraud = dfClaims['fraud_reported'] == 'Y'\n",
    "fraudY2 = dfClaims.loc[rowsYesFraud, ]\n",
    "\n",
    "# subset for fraud reported is no\n",
    "rowsNoFraud = dfClaims['fraud_reported'] == 'N'\n",
    "fraudN2 = dfClaims.loc[rowsNoFraud, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>umbrella_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52761.94000</td>\n",
       "      <td>1.487000</td>\n",
       "      <td>1136.000000</td>\n",
       "      <td>1.101000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>26401.53319</td>\n",
       "      <td>1.111335</td>\n",
       "      <td>611.864673</td>\n",
       "      <td>2.297407e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>-1.000000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41812.50000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58055.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70592.50000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>114920.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.000000e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_claim_amount    witnesses  policy_deductable  umbrella_limit\n",
       "count          1000.00000  1000.000000        1000.000000    1.000000e+03\n",
       "mean          52761.94000     1.487000        1136.000000    1.101000e+06\n",
       "std           26401.53319     1.111335         611.864673    2.297407e+06\n",
       "min             100.00000     0.000000         500.000000   -1.000000e+06\n",
       "25%           41812.50000     1.000000         500.000000    0.000000e+00\n",
       "50%           58055.00000     1.000000        1000.000000    0.000000e+00\n",
       "75%           70592.50000     2.000000        2000.000000    0.000000e+00\n",
       "max          114920.00000     3.000000        2000.000000    1.000000e+07"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataset with quantitative variables - full dataset\n",
    "dfClaims_quant = dfClaims.filter(['months_bf_incident', 'total_claim_amount', 'witnesses', 'policy_deductable', 'umbrella_limit'], axis=1)\n",
    "dfClaims_quant.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataset with quantitative variables - fraud reported\n",
    "fraudY2_quant = fraudY2.filter(['months_bf_incident', 'total_claim_amount', 'vehicle_claim', 'witnesses', 'number_of_vehicles_involved', 'policy_deductable', 'umbrella_limit'], axis=1)\n",
    "fraudY2_quant.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataset with quantitative variables - no fraud reported\n",
    "fraudN2_quant = fraudN2.filter(['months_bf_incident', 'total_claim_amount', 'vehicle_claim', 'witnesses', 'number_of_vehicles_involved', 'policy_deductable', 'umbrella_limit'], axis=1)\n",
    "fraudN2_quant.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation of quantitative features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>umbrella_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_claim_amount</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>0.022839</td>\n",
       "      <td>-0.040344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>witnesses</th>\n",
       "      <td>-0.011114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066639</td>\n",
       "      <td>-0.006738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_deductable</th>\n",
       "      <td>0.022839</td>\n",
       "      <td>0.066639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>umbrella_limit</th>\n",
       "      <td>-0.040344</td>\n",
       "      <td>-0.006738</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    total_claim_amount  witnesses  policy_deductable  \\\n",
       "total_claim_amount            1.000000  -0.011114           0.022839   \n",
       "witnesses                    -0.011114   1.000000           0.066639   \n",
       "policy_deductable             0.022839   0.066639           1.000000   \n",
       "umbrella_limit               -0.040344  -0.006738           0.010870   \n",
       "\n",
       "                    umbrella_limit  \n",
       "total_claim_amount       -0.040344  \n",
       "witnesses                -0.006738  \n",
       "policy_deductable         0.010870  \n",
       "umbrella_limit            1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataset with quantitative variables - full dataframe\n",
    "dfClaims_quant = dfClaims.filter(['months_bf_incident', 'total_claim_amount', 'witnesses', 'policy_deductable', 'umbrella_limit'], axis=1)\n",
    "dfClaims_quant.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>umbrella_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_claim_amount</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037589</td>\n",
       "      <td>-0.104484</td>\n",
       "      <td>-0.022993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>witnesses</th>\n",
       "      <td>0.037589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031163</td>\n",
       "      <td>-0.037245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_deductable</th>\n",
       "      <td>-0.104484</td>\n",
       "      <td>0.031163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>umbrella_limit</th>\n",
       "      <td>-0.022993</td>\n",
       "      <td>-0.037245</td>\n",
       "      <td>-0.011936</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    total_claim_amount  witnesses  policy_deductable  \\\n",
       "total_claim_amount            1.000000   0.037589          -0.104484   \n",
       "witnesses                     0.037589   1.000000           0.031163   \n",
       "policy_deductable            -0.104484   0.031163           1.000000   \n",
       "umbrella_limit               -0.022993  -0.037245          -0.011936   \n",
       "\n",
       "                    umbrella_limit  \n",
       "total_claim_amount       -0.022993  \n",
       "witnesses                -0.037245  \n",
       "policy_deductable        -0.011936  \n",
       "umbrella_limit            1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataset with quantitative variables - fraud reported\n",
    "fraudY2_quant = fraudY2.filter(['months_bf_incident', 'total_claim_amount', 'witnesses', 'policy_deductable', 'umbrella_limit'], axis=1)\n",
    "fraudY2_quant.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>umbrella_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_claim_amount</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032933</td>\n",
       "      <td>0.052804</td>\n",
       "      <td>-0.059233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>witnesses</th>\n",
       "      <td>-0.032933</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077246</td>\n",
       "      <td>-0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy_deductable</th>\n",
       "      <td>0.052804</td>\n",
       "      <td>0.077246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>umbrella_limit</th>\n",
       "      <td>-0.059233</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.018364</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    total_claim_amount  witnesses  policy_deductable  \\\n",
       "total_claim_amount            1.000000  -0.032933           0.052804   \n",
       "witnesses                    -0.032933   1.000000           0.077246   \n",
       "policy_deductable             0.052804   0.077246           1.000000   \n",
       "umbrella_limit               -0.059233  -0.000106           0.018364   \n",
       "\n",
       "                    umbrella_limit  \n",
       "total_claim_amount       -0.059233  \n",
       "witnesses                -0.000106  \n",
       "policy_deductable         0.018364  \n",
       "umbrella_limit            1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataset with quantitative variables - no fraud reported\n",
    "fraudN2_quant = fraudN2.filter(['months_bf_incident', 'total_claim_amount', 'witnesses', 'policy_deductable', 'umbrella_limit'], axis=1)\n",
    "fraudN2_quant.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Point-biserial correlation is used for correlation between the binary fraud reported variable and continuous variables.  None of the point-biserial correlations for the fraud_reported feature are strong.  However, the p-value for umbrella limit shows that it may be significant.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# factorize categorical from strings to numberics in dfClaims df\n",
    "dfClaims['fraud_reported_f'] = pd.factorize(dfClaims.fraud_reported)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointbiserialrResult(correlation=-0.16365148901480392, pvalue=1.9529359591865256e-07)\n",
      "PointbiserialrResult(correlation=-0.05862165764044373, pvalue=0.06387450991600865)\n",
      "PointbiserialrResult(correlation=-0.020543512494971355, pvalue=0.5164037490553202)\n",
      "PointbiserialrResult(correlation=-0.04949667970707168, pvalue=0.11776506385185714)\n",
      "PointbiserialrResult(correlation=-0.014817347521118537, pvalue=0.6397807865912944)\n"
     ]
    }
   ],
   "source": [
    "pbcClaimAmt = stats.pointbiserialr(dfClaims.fraud_reported_f, dfClaims.total_claim_amount)\n",
    "print(pbcClaimAmt)\n",
    "\n",
    "pbcUmb = stats.pointbiserialr(dfClaims.fraud_reported_f, dfClaims.umbrella_limit)\n",
    "print(pbcUmb)\n",
    "\n",
    "pbcMonths = stats.pointbiserialr(dfClaims.fraud_reported_f, dfClaims.months_as_customer)\n",
    "print(pbcMonths)\n",
    "\n",
    "pbcWitn = stats.pointbiserialr(dfClaims.fraud_reported_f, dfClaims.witnesses)\n",
    "print(pbcWitn)\n",
    "\n",
    "pbcDeduc = stats.pointbiserialr(dfClaims.fraud_reported_f, dfClaims.policy_deductable)\n",
    "print(pbcDeduc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the cleaned df to a csv file\n",
    "dfClaims.to_csv('dfClaims.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Address skew in quantitative features with log-transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-transformation\n",
    "# first need to convert values in capital_loss to remove negative values before log_transformation.  \n",
    "#     Add the largest negative number to all values.\n",
    "\n",
    "# largest negative value\n",
    "largestNeg = dfClaims['capital_loss'].min()\n",
    "\n",
    "#dfClaims_quantVars['capital_loss'] = dfClaims_quantVars['capital_loss'].apply(lambda x: x + 1 - min(x))\n",
    "dfClaims_quantVars['capital_loss'] = dfClaims_quantVars['capital_loss'] - largestNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfClaims_quantVars['capital_loss'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-transformation - cont\n",
    "\n",
    "# now without negative values, can use log_transformation\n",
    "\n",
    "def log_transformation(data):\n",
    "    return data.apply(np.log1p)\n",
    "\n",
    "dfClaims_quantVars['months_as_customer'] = log_transformation(dfClaims_quantVars['months_as_customer'])\n",
    "dfClaims_quantVars['age'] = log_transformation(dfClaims_quantVars['age'])\n",
    "dfClaims_quantVars['policy_deductable'] = log_transformation(dfClaims_quantVars['policy_deductable'])\n",
    "dfClaims_quantVars['policy_annual_premium'] = log_transformation(dfClaims_quantVars['policy_annual_premium'])\n",
    "dfClaims_quantVars['umbrella_limit'] = log_transformation(dfClaims_quantVars['umbrella_limit'])\n",
    "dfClaims_quantVars['capital_gains'] = log_transformation(dfClaims_quantVars['capital_gains'])\n",
    "dfClaims_quantVars['capital_loss'] = log_transformation(dfClaims_quantVars['capital_loss'])\n",
    "dfClaims_quantVars['incident_hour_of_the_day'] = log_transformation(dfClaims_quantVars['incident_hour_of_the_day'])\n",
    "dfClaims_quantVars['number_of_vehicles_involved'] = log_transformation(dfClaims_quantVars['number_of_vehicles_involved'])\n",
    "dfClaims_quantVars['bodily_injuries'] = log_transformation(dfClaims_quantVars['bodily_injuries'])\n",
    "dfClaims_quantVars['witnesses'] = log_transformation(dfClaims_quantVars['witnesses'])\n",
    "dfClaims_quantVars['total_claim_amount'] = log_transformation(dfClaims_quantVars['total_claim_amount'])\n",
    "dfClaims_quantVars['injury_claim'] = log_transformation(dfClaims_quantVars['injury_claim'])\n",
    "dfClaims_quantVars['property_claim'] = log_transformation(dfClaims_quantVars['property_claim'])\n",
    "dfClaims_quantVars['vehicle_claim'] = log_transformation(dfClaims_quantVars['vehicle_claim'])\n",
    "dfClaims_quantVars['auto_year'] = log_transformation(dfClaims_quantVars['auto_year'])\n",
    "dfClaims_quantVars['csl_bodily'] = log_transformation(dfClaims_quantVars['csl_bodily'])\n",
    "dfClaims_quantVars['csl_prop'] = log_transformation(dfClaims_quantVars['csl_prop'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to scale features for modeling purposes because of of the wide ranges of values and because PCA analysis requires scaling of features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "features= StandardScaler().fit_transform(dfClaims_quantVars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some of the variables are highly correlated to a great extent and there are still a great many features. Conduct PCA analysis for dimensionalty reduction and to address multicollinearity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "# https://www.datacamp.com/community/tutorials/principal-component-analysis-in-python\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=0.99, whiten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pca = pca.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original number of features: 18\n"
     ]
    }
   ],
   "source": [
    "print(\"original number of features:\", features.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduced number of features: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"reduced number of features:\", features_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the original feature names that compose the PCA components\n",
    "\n",
    "model = PCA(n_components=16, whiten=True).fit(dfClaims_quantVars)\n",
    "X_pc = model.transform(dfClaims_quantVars)\n",
    "\n",
    "# number of components\n",
    "n_pcs= model.components_.shape[0]\n",
    "\n",
    "# get the index of the most important feature on EACH component\n",
    "# LIST COMPREHENSION HERE\n",
    "most_important = [np.abs(model.components_[i]).argmax() for i in range(n_pcs)]\n",
    "\n",
    "initial_feature_names = ['months_as_customer', 'age', 'policy_deductable', 'policy_annual_premium', 'umbrella_limit', 'capital_gains', 'capital_loss', 'incident_hour_of_the_day', 'number_of_vehicles_involved', 'bodily_injuries', 'witnesses', 'total_claim_amount', 'injury_claim', 'property_claim', 'vehicle_claim', 'auto_year', 'csl_bodily', 'csl_prop']\n",
    "\n",
    "# get the names\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "\n",
    "# LIST COMPREHENSION HERE AGAIN\n",
    "dic = {'PC{}'.format(i+1): most_important_names[i] for i in range(n_pcs)}\n",
    "\n",
    "# build the dataframe\n",
    "impPca = pd.DataFrame(sorted(dic.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0                            1\n",
      "0    PC1               umbrella_limit\n",
      "1   PC10                 capital_loss\n",
      "2   PC11                    witnesses\n",
      "3   PC12              bodily_injuries\n",
      "4   PC13  number_of_vehicles_involved\n",
      "5   PC14        policy_annual_premium\n",
      "6   PC15                          age\n",
      "7   PC16                     csl_prop\n",
      "8    PC2                capital_gains\n",
      "9    PC3                 injury_claim\n",
      "10   PC4                 injury_claim\n",
      "11   PC5           months_as_customer\n",
      "12   PC6           months_as_customer\n",
      "13   PC7                   csl_bodily\n",
      "14   PC8     incident_hour_of_the_day\n",
      "15   PC9            policy_deductable\n"
     ]
    }
   ],
   "source": [
    "print(impPca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dataframe with PCA features\n",
    "pcaDf = pd.DataFrame(data = features_pca, columns = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', \n",
    "                                                     'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>PC11</th>\n",
       "      <th>PC12</th>\n",
       "      <th>PC13</th>\n",
       "      <th>PC14</th>\n",
       "      <th>PC15</th>\n",
       "      <th>PC16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.483900</td>\n",
       "      <td>0.059614</td>\n",
       "      <td>-0.955847</td>\n",
       "      <td>-0.025665</td>\n",
       "      <td>0.591583</td>\n",
       "      <td>0.153248</td>\n",
       "      <td>-0.691812</td>\n",
       "      <td>0.295531</td>\n",
       "      <td>0.442051</td>\n",
       "      <td>0.051544</td>\n",
       "      <td>-1.429445</td>\n",
       "      <td>-0.710023</td>\n",
       "      <td>-0.892472</td>\n",
       "      <td>-0.512373</td>\n",
       "      <td>0.248171</td>\n",
       "      <td>0.309361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.854001</td>\n",
       "      <td>-0.343416</td>\n",
       "      <td>-0.567494</td>\n",
       "      <td>-0.813326</td>\n",
       "      <td>-0.787381</td>\n",
       "      <td>0.233525</td>\n",
       "      <td>1.377591</td>\n",
       "      <td>-1.209882</td>\n",
       "      <td>-2.257126</td>\n",
       "      <td>0.971511</td>\n",
       "      <td>-0.183259</td>\n",
       "      <td>0.695840</td>\n",
       "      <td>0.060263</td>\n",
       "      <td>-0.339776</td>\n",
       "      <td>-0.659630</td>\n",
       "      <td>-0.106189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.161242</td>\n",
       "      <td>-0.969355</td>\n",
       "      <td>0.703681</td>\n",
       "      <td>1.157773</td>\n",
       "      <td>0.721673</td>\n",
       "      <td>1.432304</td>\n",
       "      <td>1.082024</td>\n",
       "      <td>-1.579674</td>\n",
       "      <td>-0.213965</td>\n",
       "      <td>-0.475423</td>\n",
       "      <td>-1.212564</td>\n",
       "      <td>-1.254666</td>\n",
       "      <td>1.275487</td>\n",
       "      <td>0.537676</td>\n",
       "      <td>-0.346111</td>\n",
       "      <td>-1.258978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.303895</td>\n",
       "      <td>0.127025</td>\n",
       "      <td>-0.483588</td>\n",
       "      <td>1.492848</td>\n",
       "      <td>0.668958</td>\n",
       "      <td>1.380413</td>\n",
       "      <td>1.505900</td>\n",
       "      <td>-0.622263</td>\n",
       "      <td>-0.473612</td>\n",
       "      <td>1.393627</td>\n",
       "      <td>-0.764645</td>\n",
       "      <td>-0.559678</td>\n",
       "      <td>-0.876623</td>\n",
       "      <td>-0.633961</td>\n",
       "      <td>1.067398</td>\n",
       "      <td>-0.204994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.675210</td>\n",
       "      <td>1.074260</td>\n",
       "      <td>-1.002100</td>\n",
       "      <td>0.089537</td>\n",
       "      <td>-0.090308</td>\n",
       "      <td>0.356090</td>\n",
       "      <td>0.765507</td>\n",
       "      <td>-1.244979</td>\n",
       "      <td>-0.820860</td>\n",
       "      <td>2.178117</td>\n",
       "      <td>0.591020</td>\n",
       "      <td>-1.618367</td>\n",
       "      <td>-0.063689</td>\n",
       "      <td>0.275966</td>\n",
       "      <td>-0.648299</td>\n",
       "      <td>0.196565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0 -0.483900  0.059614 -0.955847 -0.025665  0.591583  0.153248 -0.691812   \n",
       "1  1.854001 -0.343416 -0.567494 -0.813326 -0.787381  0.233525  1.377591   \n",
       "2 -0.161242 -0.969355  0.703681  1.157773  0.721673  1.432304  1.082024   \n",
       "3 -0.303895  0.127025 -0.483588  1.492848  0.668958  1.380413  1.505900   \n",
       "4  1.675210  1.074260 -1.002100  0.089537 -0.090308  0.356090  0.765507   \n",
       "\n",
       "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
       "0  0.295531  0.442051  0.051544 -1.429445 -0.710023 -0.892472 -0.512373   \n",
       "1 -1.209882 -2.257126  0.971511 -0.183259  0.695840  0.060263 -0.339776   \n",
       "2 -1.579674 -0.213965 -0.475423 -1.212564 -1.254666  1.275487  0.537676   \n",
       "3 -0.622263 -0.473612  1.393627 -0.764645 -0.559678 -0.876623 -0.633961   \n",
       "4 -1.244979 -0.820860  2.178117  0.591020 -1.618367 -0.063689  0.275966   \n",
       "\n",
       "       PC15      PC16  \n",
       "0  0.248171  0.309361  \n",
       "1 -0.659630 -0.106189  \n",
       "2 -0.346111 -1.258978  \n",
       "3  1.067398 -0.204994  \n",
       "4 -0.648299  0.196565  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcaDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 16)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcaDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add categorical variables back to df\n",
    "\n",
    "pcaDf['policy_state'] = dfClaims['policy_state'] \n",
    "pcaDf['insured_sex'] = dfClaims['insured_sex']\n",
    "pcaDf['insured_education_level'] = dfClaims['insured_education_level']\n",
    "pcaDf['insured_occupation'] = dfClaims['insured_occupation']\n",
    "pcaDf['insured_hobbies'] = dfClaims['insured_hobbies']\n",
    "pcaDf['insured_relationship'] = dfClaims['insured_relationship']\n",
    "pcaDf['incident_type'] = dfClaims['incident_type']\n",
    "pcaDf['collision_type'] = dfClaims['collision_type'] \n",
    "pcaDf['incident_severity'] = dfClaims['incident_severity']\n",
    "pcaDf['authorities_contacted'] = dfClaims['authorities_contacted']\n",
    "pcaDf['incident_state'] = dfClaims['incident_state']\n",
    "pcaDf['incident_city'] = dfClaims['incident_city']\n",
    "pcaDf['property_damage'] = dfClaims['property_damage'] \n",
    "pcaDf['police_report_available'] = dfClaims['police_report_available']\n",
    "pcaDf['auto_make'] = dfClaims['auto_make']\n",
    "pcaDf['auto_model'] = dfClaims['auto_model']\n",
    "pcaDf['fraud_reported'] = dfClaims['fraud_reported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_state has 1 missing value(s)\n",
      "insured_sex has 1 missing value(s)\n",
      "insured_education_level has 1 missing value(s)\n",
      "insured_occupation has 1 missing value(s)\n",
      "insured_hobbies has 1 missing value(s)\n",
      "insured_relationship has 1 missing value(s)\n",
      "incident_type has 1 missing value(s)\n",
      "collision_type has 1 missing value(s)\n",
      "incident_severity has 1 missing value(s)\n",
      "authorities_contacted has 1 missing value(s)\n",
      "incident_state has 1 missing value(s)\n",
      "incident_city has 1 missing value(s)\n",
      "property_damage has 1 missing value(s)\n",
      "police_report_available has 1 missing value(s)\n",
      "auto_make has 1 missing value(s)\n",
      "auto_model has 1 missing value(s)\n",
      "fraud_reported has 1 missing value(s)\n"
     ]
    }
   ],
   "source": [
    "# check for missing values in PCA dataframe\n",
    "for c in pcaDf.columns:\n",
    "    miss = pcaDf[c].isnull().sum()\n",
    "    if miss>0:\n",
    "        print(\"{} has {} missing value(s)\".format(c,miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 33)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcaDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
      "290 -0.275614  0.108439  0.747717  2.217323 -0.913769 -1.153043  0.527141   \n",
      "\n",
      "          PC8       PC9      PC10  ...  collision_type  incident_severity  \\\n",
      "290  1.789114 -1.387921 -0.343604  ...             NaN                NaN   \n",
      "\n",
      "     authorities_contacted  incident_state  incident_city  property_damage  \\\n",
      "290                    NaN             NaN            NaN              NaN   \n",
      "\n",
      "    police_report_available auto_make auto_model fraud_reported  \n",
      "290                     NaN       NaN        NaN            NaN  \n",
      "\n",
      "[1 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# the pcaDf now has a null row for some reason\n",
    "is_NaN = pcaDf.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = pcaDf[row_has_NaN]\n",
    "\n",
    "print(rows_with_NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the new null row\n",
    "pcaDf =pcaDf.drop(pcaDf.index[290])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [PC1, PC2, PC3, PC4, PC5, PC6, PC7, PC8, PC9, PC10, PC11, PC12, PC13, PC14, PC15, PC16, policy_state, insured_sex, insured_education_level, insured_occupation, insured_hobbies, insured_relationship, incident_type, collision_type, incident_severity, authorities_contacted, incident_state, incident_city, property_damage, police_report_available, auto_make, auto_model, fraud_reported]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "is_NaN = pcaDf.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = pcaDf[row_has_NaN]\n",
    "\n",
    "print(rows_with_NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the revised pca df to a csv file\n",
    "pcaDf.to_csv('pcaClaimsLog.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Instead of running the above code multiple times, import the dataframes for subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scaled, transformed and PCA df\n",
    "pcaDF = pd.read_csv('pcaClaimsLog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cleaned df without re-running the cleaning code\n",
    "df = pd.read_csv('dfClaims.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
